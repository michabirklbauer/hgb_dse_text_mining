{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c6dc631-bce1-4e18-b15a-c8840c7bf71b",
   "metadata": {},
   "source": [
    "# Sarcasm Detection in News Headlines with Neural Nets\n",
    "\n",
    "### Loading the data\n",
    "\n",
    "In the following we will use the **News Headlines Dataset For Sarcasm Detection** by *Rishabh Misra* to build a classifier that can distinguish sarcastic news from serious ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0116b157-752b-4602-901a-c763662d9e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "# 0 - no sarcasm, 1 - sarcasm\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/michabirklbauer/hgb_dse_text_mining/master/data/Sarcasm/sarcasm.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c0eff5-24ea-450b-b6c1-08eb47ec8bfd",
   "metadata": {},
   "source": [
    "### A glimpse at class distributions and baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cba2a3-ab75-416c-a9df-74fa593a8379",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Baseline: \", data[\"Label\"].value_counts()[0] / data.shape[0])\n",
    "data[\"Label\"].value_counts().plot(kind = \"bar\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b9099d-4780-4590-a84e-8793950de0e7",
   "metadata": {},
   "source": [
    "### Splitting data into a training, validation and test partition to be able to evaluate our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bcab17-ad88-4ef6-a08e-a549fdc466bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_test, test = train_test_split(data, test_size = 0.2, random_state = 1337)\n",
    "train, val = train_test_split(not_test, test_size = 0.3, random_state = 1337)\n",
    "print(train.shape)\n",
    "print(val.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cbdfae-7c89-4b49-aa9e-f139121bdcbb",
   "metadata": {},
   "source": [
    "### We will use Keras to build our neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddac79b1-4116-4afa-a33e-b4d573bf7df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe515f87-cdd4-44fb-b212-8a28333b0aff",
   "metadata": {},
   "source": [
    "### Model parameters\n",
    "\n",
    "- We will use a vocabulary size of 10 000\n",
    "- We will create word vectors of length 16\n",
    "- Our texts will be max 100 words long\n",
    "  - If they are shorter we will zero-pad them at the end\n",
    "  - If they are longer we will truncate them to 100 from the end\n",
    "- Our Out-Of-Vocabulary token will be \\<OOV>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693304c7-8a84-4a36-b034-8d76553ad26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "embedding_dim = 16\n",
    "max_length = 100\n",
    "trunc_type = \"post\"\n",
    "padding_type = \"post\"\n",
    "oov_token = \"<OOV>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b86a06c-db98-4df1-9c52-5bf228067cad",
   "metadata": {},
   "source": [
    "### Fit the tokenizer to the texts and generate equal length sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce0952f-dd21-40e8-869d-2c1d4a2e3fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token = oov_token)\n",
    "tokenizer.fit_on_texts(train[\"Headline\"])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "training_sequences = tokenizer.texts_to_sequences(train[\"Headline\"])\n",
    "training_padded = pad_sequences(training_sequences, maxlen = max_length, padding = padding_type, truncating = trunc_type)\n",
    "\n",
    "validation_sequences = tokenizer.texts_to_sequences(val[\"Headline\"])\n",
    "validation_padded = pad_sequences(validation_sequences, maxlen = max_length, padding = padding_type, truncating = trunc_type)\n",
    "\n",
    "testing_sequences = tokenizer.texts_to_sequences(test[\"Headline\"])\n",
    "testing_padded = pad_sequences(testing_sequences, maxlen = max_length, padding = padding_type, truncating = trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4ec6d3-1c21-4878-be1d-0b2c1f3c7a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fe7b01-36eb-41c7-80bc-10a67f622a6a",
   "metadata": {},
   "source": [
    "Bigger index of the word -> less frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0312d9df-d5e5-4a78-9fd9-4053f6d52209",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sequences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e75a1ee-42c4-43e0-8021-8aad08dc903e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_padded[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d756b6-6961-4846-abcf-bb01501a6be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_padded = np.array(training_padded)\n",
    "training_labels = np.array(train[\"Label\"])\n",
    "validation_padded = np.array(validation_padded)\n",
    "validation_labels = np.array(val[\"Label\"])\n",
    "testing_padded = np.array(testing_padded)\n",
    "testing_labels = np.array(test[\"Label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1849da11-6b91-4aa1-96ee-7cb45df480c1",
   "metadata": {},
   "source": [
    "### Building our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5916e4dd-50f8-45ce-9254-d098f8569e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length = max_length))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(24, activation = \"relu\"))\n",
    "model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "# callbacks\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "callbacks = []\n",
    "callbacks.append(EarlyStopping(monitor = \"val_loss\", patience = 5, verbose = 0, mode = \"auto\"))\n",
    "callbacks.append(ModelCheckpoint(\"sarcasm_check_.h5\", save_best_only = True, monitor = \"val_loss\", mode = \"min\"))\n",
    "\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20927aa-ea72-4f41-a814-c86bcc53f39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86d445a-bef7-4729-b945-1d79d2b0368c",
   "metadata": {},
   "source": [
    "### Training the model on our data\n",
    "\n",
    "Compare the training with and without callbacks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52791e2-0a2d-46be-85df-1a2bde458388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbd6a3f-a632-4434-bede-24de0a7ecd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(training_padded, training_labels, epochs = 30 , validation_data = (validation_padded, validation_labels), callbacks = callbacks, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e257878e-6759-4649-ac2b-32dc15efda17",
   "metadata": {},
   "source": [
    "### Plot training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b59dd0-61ba-49bd-b0b4-41f37756a62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, metric):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history[\"val_\" + metric])\n",
    "    plt.title(\"Model \" +  metric)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, \"val_\" + metric])\n",
    "    plt.show()\n",
    "    \n",
    "plot_graphs(history, \"accuracy\")\n",
    "plot_graphs(history, \"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fd5585-8a8a-469e-93e8-dd5c67e2d6bc",
   "metadata": {},
   "source": [
    "### Load best-on-validation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1027c1-03cc-4eb0-bbb3-faab911d8653",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"sarcasm_check_.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b185bce-f6cb-4cc4-a1f9-82cfe62a3f03",
   "metadata": {},
   "source": [
    "### Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df7a3f2-7ae3-4e89-b7c4-e678872ed650",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"single woman getting all dolled up to watch room full of people make out this new year's eve\", \"there were some things to cheer in donald trump's wild press conference\"]\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "padded = pad_sequences(sequences, maxlen = max_length, padding = padding_type, truncating = trunc_type)\n",
    "print(model.predict(padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deae961-d698-40b7-93b1-4a5e7699d57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = np.where(model.predict(training_padded) > 0.5, 1, 0)\n",
    "predictions_val = np.where(model.predict(validation_padded) > 0.5, 1, 0)\n",
    "predictions_test = np.where(model.predict(testing_padded) > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4d9567-b73b-404e-842d-470e03954870",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a6309c-605e-4c1c-8144-c29ed9619b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Accuracy: \", accuracy_score(train[\"Label\"], predictions_train))\n",
    "print(\"Validation Accuracy: \", accuracy_score(val[\"Label\"], predictions_val))\n",
    "print(\"Testing Accuracy: \", accuracy_score(test[\"Label\"], predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd277bb-53d4-4da1-bf99-fd39ef90e037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize = False, title = \"Confusion matrix\", cmap = plt.cm.Blues):\n",
    "\n",
    "    plt.imshow(cm, interpolation = \"nearest\", cmap = cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation = 45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype(\"float\") / cm.sum(axis = 1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment = \"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylim(len(cm) - 0.5, -0.5)\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    \n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129df077-babf-4ea2-b1b0-6f6a741abd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = confusion_matrix(train[\"Label\"], predictions_train)\n",
    "\n",
    "plt.figure()\n",
    "plot = plot_confusion_matrix(conf, classes = [0, 1], title = \"Confusion Matrix - Training Split\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f60fea-4c23-481c-97f5-932263c8a5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = confusion_matrix(val[\"Label\"], predictions_val)\n",
    "\n",
    "plt.figure()\n",
    "plot = plot_confusion_matrix(conf, classes = [0, 1], title = \"Confusion Matrix - Validation Split\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6410b7-4347-4c4b-8935-9ebfe0e0489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = confusion_matrix(test[\"Label\"], predictions_test)\n",
    "\n",
    "plt.figure()\n",
    "plot = plot_confusion_matrix(conf, classes = [0, 1], title = \"Confusion Matrix - Testing Split\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9aecf6-1229-4b71-a0c3-67313a8f2c18",
   "metadata": {},
   "source": [
    "### By generating a reverse index we can also decode our sequences again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f00f3c1-94a0-4a32-b633-a06e0c6fdb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_sentence(text):\n",
    "    return \" \".join([reverse_word_index.get(i, \"?\") for i in text])\n",
    "\n",
    "print(decode_sentence(training_padded[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0385b188-1b0b-49dc-8b99-08a69ce7b104",
   "metadata": {},
   "source": [
    "### ...combining that with the weights from our embedding layer we can extract the word vectors that we trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91315deb-7cf1-41a6-9be5-1e7874598d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = model.layers[0]\n",
    "weights = e.get_weights()[0]\n",
    "print(weights.shape) # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c300b49-c1c1-4497-8790-e1c0c4ea26e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "out_v = io.open(\"vecs.tsv\", \"w\", encoding = \"utf-8\")\n",
    "out_m = io.open(\"meta.tsv\", \"w\", encoding = \"utf-8\")\n",
    "for word_num in range(1, vocab_size):\n",
    "    word = reverse_word_index[word_num]\n",
    "    embeddings = weights[word_num]\n",
    "    out_v.write(\"\\t\".join([str(x) for x in embeddings]) + \"\\n\")\n",
    "    out_m.write(word + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b12fc33-e907-4638-96a3-b60afdb4ec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set colab to true and run this cell if you are working in Google Colab to download the generated files\n",
    "colab = False\n",
    "if colab:\n",
    "    try:\n",
    "        from google.colab import files\n",
    "    except ImportError:\n",
    "        pass\n",
    "    else:\n",
    "        files.download(\"vecs.tsv\")\n",
    "        files.download(\"meta.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bbc6fb-3469-4567-86b4-4c400e3ed999",
   "metadata": {
    "tags": []
   },
   "source": [
    "### We can load these files in [http://projector.tensorflow.org/](http://projector.tensorflow.org/) to visualize our embeddings\n",
    "\n",
    "When we sphereize this data we get two clusters because we did binary classification.\n",
    "\n",
    "And clicking a word will show you the closest words in the vector space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34543fef-d7c5-440f-9f45-07e8028802a0",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with Transformer Models\n",
    "\n",
    "### Loading the data\n",
    "\n",
    "For this task we will use a sample of the **Amazon Fine Food Reviews Dataset** by *Stanford Network Analysis Project*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25515b70-cb4f-46c6-9416-39841bc1091a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/michabirklbauer/hgb_dse_text_mining/master/data/AmazonReviews/Reviews_sample.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeee1c3-4311-4040-a89b-7689929d6aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = data[\"Text\"][0]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f92b5ea-38e9-4dca-975a-7c766ee124c7",
   "metadata": {},
   "source": [
    "### We will use TensorFlow models from the *transformers* package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1235ddb8-987d-4f96-960c-bb86289eceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94ebf11-efac-4b69-ba90-9abfd0d369aa",
   "metadata": {},
   "source": [
    "### Loading roBERTa\n",
    "\n",
    "[https://ai.facebook.com/blog/roberta-an-optimized-method-for-pretraining-self-supervised-nlp-systems/](https://ai.facebook.com/blog/roberta-an-optimized-method-for-pretraining-self-supervised-nlp-systems/)\n",
    "\n",
    "[https://arxiv.org/abs/1907.11692](https://arxiv.org/abs/1907.11692)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a75108-6dfc-43e8-946f-e1270992ee4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b97ee98-6d85-4f3a-925d-7723342cb186",
   "metadata": {},
   "source": [
    "### Getting roBERTa predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bad936c-9f45-4ddd-a134-b6c8a6283873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity_scores_roberta(example):\n",
    "    encoded_text = tokenizer(example, return_tensors = \"tf\")\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].numpy()\n",
    "    scores = softmax(scores)\n",
    "    scores_dict = {\n",
    "        \"roberta_neg\" : scores[0],\n",
    "        \"roberta_neu\" : scores[1],\n",
    "        \"roberta_pos\" : scores[2]\n",
    "    }\n",
    "    return scores_dict\n",
    "\n",
    "print(example)\n",
    "print(polarity_scores_roberta(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03baa806-94a0-4d8b-9084-c1f3df2c7deb",
   "metadata": {},
   "source": [
    "### Sentiment Analysis in 3 lines of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efeedd4-02bf-4487-b32b-384072f891e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sent_pipeline = pipeline(\"sentiment-analysis\")\n",
    "sent_pipeline(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c459f975-3a78-4e6e-ab45-11f9321f4c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
