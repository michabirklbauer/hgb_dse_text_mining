{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ef4d8ec-b651-43cd-b92a-7676e3fc8ec6",
   "metadata": {},
   "source": [
    "### Loading our data\n",
    "\n",
    "For the following exercise we will use the word count matrix representation and only use a small subset of our data since we will implement a naiveBayes classifier - which is a \"lazy learner\" and so predictions will be rather slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c7efa9f-be80-4108-9387-6cd68255c89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "classes_en = {1: \"World\", 2: \"Sports\", 3: \"Business\", 4: \"Sci/Tech\"}\n",
    "train_en = pd.read_csv(\"https://raw.githubusercontent.com/michabirklbauer/hgb_dse_text_mining/master/data/AGNews/train.csv\", \n",
    "                       names = [\"Label\", \"Title\", \"Article\"],\n",
    "                       encoding = \"utf-8\")\n",
    "test_en = pd.read_csv(\"https://raw.githubusercontent.com/michabirklbauer/hgb_dse_text_mining/master/data/AGNews/test.csv\", \n",
    "                      names = [\"Label\", \"Title\", \"Article\"],\n",
    "                      encoding = \"utf-8\")\n",
    "\n",
    "sample = train_en.sample(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f007c515-5a39-4ad2-b904-bdca9a21df0e",
   "metadata": {},
   "source": [
    "### Splitting data into a training dataset and a test dataset\n",
    "\n",
    "*Note:* Data splitting should be your first step in any data science project that involves some kind of machine learning, doing transformations - even something like word counts - will inherently introduce bias and make the calculated generalization error on the test datast less meaningful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2c52bfe-0d55-4e4b-b745-6805cdbe46a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65, 3)\n",
      "(35, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Title</th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42936</th>\n",
       "      <td>3</td>\n",
       "      <td>JoS. A. Bank 3Q Profit Rises 19 Percent</td>\n",
       "      <td>Men #39;s apparel retailer Joseph A. Bank Clot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42920</th>\n",
       "      <td>4</td>\n",
       "      <td>New defense consortium aims for greater system...</td>\n",
       "      <td>The Network Centric Operations Industry Consor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66194</th>\n",
       "      <td>2</td>\n",
       "      <td>Mariners name Hargrove as new manager</td>\n",
       "      <td>SEATTLE -- Mike Hargrove has been named manage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109156</th>\n",
       "      <td>2</td>\n",
       "      <td>Government would back move to punish Jones</td>\n",
       "      <td>THE Australian Government said yesterday it wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100324</th>\n",
       "      <td>3</td>\n",
       "      <td>Urgent meeting in Microsoft case</td>\n",
       "      <td>A new round has opened in the European Commiss...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Label                                              Title  \\\n",
       "42936       3            JoS. A. Bank 3Q Profit Rises 19 Percent   \n",
       "42920       4  New defense consortium aims for greater system...   \n",
       "66194       2              Mariners name Hargrove as new manager   \n",
       "109156      2         Government would back move to punish Jones   \n",
       "100324      3                   Urgent meeting in Microsoft case   \n",
       "\n",
       "                                                  Article  \n",
       "42936   Men #39;s apparel retailer Joseph A. Bank Clot...  \n",
       "42920   The Network Centric Operations Industry Consor...  \n",
       "66194   SEATTLE -- Mike Hargrove has been named manage...  \n",
       "109156  THE Australian Government said yesterday it wo...  \n",
       "100324  A new round has opened in the European Commiss...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(sample, test_size = 0.35, random_state = 1337)\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736cb8f5-3c0b-4a93-b207-e66e6022c5bc",
   "metadata": {},
   "source": [
    "### Creating the word count matrices\n",
    "\n",
    "Notice that we will not fit_transform the test data but apply the same transformation that we use for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e50b0510-2c09-4ec6-9e28-b2a8933197e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65, 943)\n",
      "(35, 943)\n",
      "(943,)\n"
     ]
    }
   ],
   "source": [
    "labels_train = [classes_en[int(row[\"Label\"])] for i, row in train.iterrows()]\n",
    "docs_train = [row[\"Article\"] for i, row in train.iterrows()]\n",
    "labels_test = [classes_en[int(row[\"Label\"])] for i, row in test.iterrows()]\n",
    "docs_test = [row[\"Article\"] for i, row in test.iterrows()]\n",
    "\n",
    "from nltk.corpus import stopwords as nltkStopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "stopwords_en = list(nltkStopwords.words(\"english\"))\n",
    "count_vectorizer = CountVectorizer(strip_accents = \"unicode\",\n",
    "                                   stop_words = stopwords_en)\n",
    "\n",
    "X_train = count_vectorizer.fit_transform(docs_train)\n",
    "X_test = count_vectorizer.transform(docs_test)\n",
    "counts_features_names = count_vectorizer.get_feature_names_out()\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(counts_features_names.shape)\n",
    "\n",
    "counts_train = pd.DataFrame(X_train.A, columns = counts_features_names)\n",
    "counts_train[\"Label\"] = labels_train\n",
    "counts_test = pd.DataFrame(X_test.A, columns = counts_features_names)\n",
    "counts_test[\"Label\"] = labels_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a0647a-6646-49f8-b9ae-646b2e7aef99",
   "metadata": {},
   "source": [
    "### Use the following function to plot confusion matrices of the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6210175-dbea-4ea8-aacb-b539473c7149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize = False, title = \"Confusion matrix\", cmap = plt.cm.Blues):\n",
    "\n",
    "    plt.imshow(cm, interpolation = \"nearest\", cmap = cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation = 45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype(\"float\") / cm.sum(axis = 1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment = \"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylim(len(cm) - 0.5, -0.5)\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    \n",
    "    return cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4668bef-ea9c-4356-a4a6-f0896ec4799d",
   "metadata": {},
   "source": [
    "# **Classification**\n",
    "\n",
    "### **Exercise:** Implement a NaiveBayes classifier that follows a lazy-learning approach -> conditional probabilities are not saved but calculated on demand. A class skeleton with documentation is given which you *may* use. But you can also come up with your own approach!\n",
    "\n",
    "**NaiveBayes Classifier Implementation - Documentation:**\n",
    "\n",
    "*class NaiveBayes(data, target, delta=1)*\n",
    "\n",
    "- Parameters:\n",
    "  - data: a pandas dataframe (pandas.DataFrame)\n",
    "  - target: column name of response variable (string)\n",
    "  - delta: Lidstone's Law Succession's delta (int)\n",
    "      - if delta = 0 this corresponds to base NaiveBayes\n",
    "      - if delta = 1 this corresponds to Laplace Estimation\n",
    "      - DEFAULT: 1\n",
    "      \n",
    "*method predict(x, has_target=False)*\n",
    "\n",
    "- Parameters:\n",
    "  - x: a pandas series (pandas.Series)\n",
    "  - has_target: whether or not x is still labeled (bool)\n",
    "    - DEFAULT: False\n",
    "- Return:\n",
    "  - predicted label (int/string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a629cd5-7444-4b3e-b52a-afcc51657e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    \n",
    "    def __init__(self, data, target, delta=1):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.delta = delta\n",
    "        return\n",
    "    \n",
    "    def predict(self, x, has_target=False):\n",
    "        \n",
    "        data = self.data\n",
    "        target = self.target\n",
    "        delta = self.delta\n",
    "        \n",
    "        # Implement a function P(C) that returns\n",
    "        # the probability of Class C in the dataset which is\n",
    "        # nr. of rows with C / nr. of rows\n",
    "        # Hint: to get the number of rows of a pandas dataframe use df.shape[0]\n",
    "        def P(C):\n",
    "            # your code here\n",
    "\n",
    "        \n",
    "        # Implement a function P_conditional(f, F, C) that returns\n",
    "        # the conditional Probability of a Feature f having the value F, given class C which is\n",
    "        # nr. of rows that have both F and C / nr. of rows that have C\n",
    "        # (optionally + delta: (nr. of rows that have both F and C + delta)/(nr. of rows that have C + nr. of unique feature values in f * delta)\n",
    "        # ^ this is called Lidstone's Law Succession and adresses the problem of the probability going to 0 as soon as feature does not occur (very frequently)\n",
    "        def P_conditional(f, F, C):\n",
    "            # your code here\n",
    "            \n",
    "        \n",
    "        # we can retrieve our features like this\n",
    "        features = x.index.tolist()\n",
    "        if has_target:\n",
    "            features.remove(target)\n",
    "            \n",
    "        # res will be our result vector that will consist of tuples of\n",
    "        # C <-> probability\n",
    "        # So the probability the our predicted class is C\n",
    "        # in our case res will be of length 4: World, Sports, Business, Sci/Tech\n",
    "        # and each class will be associated with a probability\n",
    "        res = []\n",
    "        \n",
    "        # The Conditional Probability of class C given features f\n",
    "        # = Product of Probability of Class C and all Conditional Probabilities F of f given C\n",
    "        # for class in classes\n",
    "        for C_i in data[target].unique().tolist():\n",
    "            # calculate the probability of class C\n",
    "            r = # your code here\n",
    "            \n",
    "            # multiply the above probability of class C with the Conditional Probability of Feature f having the value F, given class C for every feature\n",
    "            for f in features:\n",
    "                r = # your code here\n",
    "                \n",
    "            res.append((r, C_i))\n",
    "        \n",
    "        # Predict class C that has highest Probability\n",
    "        res.sort(key=lambda x: x[0], reverse=True)\n",
    "        argmax = res[0][1]\n",
    "        \n",
    "        return argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2df90bb9-24d7-4590-a843-a286b6da0b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = NaiveBayes(data = counts_train, target = \"Label\", delta = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4e02ac-2fd5-485c-b623-a12df97e52d3",
   "metadata": {},
   "source": [
    "### Evaluate your implementation on the training data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "876ef0d7-7837-4ba8-94ea-9bc890762e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress bar: 100%|████████████████████████████████████████████████████████████████████| 65/65 [02:38<00:00,  2.44s/it]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas(desc = \"progress bar\")\n",
    "predictions_train = counts_train.progress_apply(lambda row: NB.predict(row, has_target = True), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d28049-9034-4106-b7e8-014a91199114",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = confusion_matrix(counts_train[\"Label\"], predictions_train)\n",
    "\n",
    "plt.figure()\n",
    "plot = plot_confusion_matrix(conf, classes = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"], title = \"Confusion matrix - Train Split\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1357cd-54ed-4b0b-a514-6d783a286a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Accuracy: \", accuracy_score(counts_train[\"Label\"], predictions_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dd8010-9777-4366-af31-6dc83cc84e25",
   "metadata": {},
   "source": [
    "### ...and on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0410697d-2f38-484c-a908-395d86eed230",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress bar: 100%|████████████████████████████████████████████████████████████████████| 35/35 [01:26<00:00,  2.48s/it]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas(desc = \"progress bar\")\n",
    "predictions_test = counts_test.progress_apply(lambda row: NB.predict(row, has_target = True), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd0ed61-856f-461d-abb0-6c8f1d9c9f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = confusion_matrix(counts_test[\"Label\"], predictions_test)\n",
    "\n",
    "plt.figure()\n",
    "plot = plot_confusion_matrix(conf, classes = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"], title = \"Confusion matrix - Test Split\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baadbb0-469b-4be2-88d8-559f17ae2b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Accuracy: \", accuracy_score(counts_test[\"Label\"], predictions_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bdd589-e7b0-465a-9490-9ed9b764842f",
   "metadata": {},
   "source": [
    "### What can you observe?\n",
    "\n",
    "Does it work well? What does accuracy in this context mean given that we have four balanced classes (and we assume that our sample is truly random)? What could be pitfalls why the classifier doesn't work well?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b4033e-cdb8-4dff-ad45-ddbc4f95fcda",
   "metadata": {},
   "source": [
    "### **Alternative/Bonus Exercise:** Implement the kNN algorithm using the TF-IDF matrix representation and using the cosine distance!\n",
    "\n",
    "Compare (the performance of) your solution to that of the kNN implementation of sklearn: [https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a06187-699b-4890-9a78-ec3b7c45ac40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
